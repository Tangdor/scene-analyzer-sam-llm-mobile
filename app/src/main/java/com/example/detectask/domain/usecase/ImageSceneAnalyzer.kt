package com.example.detectask.domain.usecase

import android.content.Context
import android.graphics.Bitmap
import android.os.Environment
import com.example.detectask.domain.SceneDescriber
import com.example.detectask.ml.llm.LlmChatClient
import com.example.detectask.ml.yolo.YoloSegmentor
import com.example.detectask.tracking.EnhancedTrackedObject
import com.example.detectask.tracking.KalmanFilter1D
import com.example.detectask.tracking.KalmanFilter2D
import com.example.detectask.ui.assistant.AssistantActivity
import com.example.detectask.ui.views.DetectionBox
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.withContext
import java.io.File

/**
 * A scene analyzer implementation that uses computer vision and language models
 * to interpret and describe the content of an input image.
 *
 * This class performs object detection, object tracking initialization,
 * and scene description using a large language model (LLM).
 *
 * @constructor Creates an [ImageSceneAnalyzer] with required ML and context dependencies.
 * @param context Android context used to initialize detectors and clients.
 */
class ImageSceneAnalyzer(context: Context) : BaseSceneAnalyzer(), SceneAnalyzer {

    private val yolo = YoloSegmentor(context)

    /**
     * The client responsible for communicating with the LLM (e.g. for generating textual summaries).
     */
    internal val llmClient = LlmChatClient(context)

    /**
     * Analyzes the given [bitmap] image using the specified [mode].
     *
     * The function performs detection using YOLO, initializes Kalman-based tracking structures,
     * generates a JSON-formatted scene summary, stores it as a file, and prepares structured output.
     *
     * @param bitmap The image to analyze.
     * @param mode The analysis mode, which controls the detail level of the scene description.
     * @return A [SceneAnalysisResult] containing detection boxes, labels, the JSON description,
     * and a file path to the saved summary.
     */
    suspend fun analyze(bitmap: Bitmap, mode: AssistantActivity.AnalysisMode): SceneAnalysisResult =
        withContext(Dispatchers.IO) {
            val detections = yolo.detect(bitmap)
            val boxes = detections.filterIsInstance<DetectionBox>()
            val labels = boxes.map { "${it.label} (%.2f)".format(it.score) }

            val tracked = boxes.mapIndexed { i, box ->
                EnhancedTrackedObject(
                    id = i + 1,
                    label = box.label,
                    kalmanPosition = KalmanFilter2D().apply {
                        initialize(box.rect.centerX(), box.rect.centerY())
                    },
                    kalmanWidth = KalmanFilter1D().apply {
                        initialize(box.rect.width())
                    },
                    kalmanHeight = KalmanFilter1D().apply {
                        initialize(box.rect.height())
                    },
                    appearanceHist = FloatArray(256),
                    lastSeenFrame = 0,
                    firstSeenFrame = 0
                )
            }

            val sceneJson = when (mode) {
                AssistantActivity.AnalysisMode.DETAILED,
                AssistantActivity.AnalysisMode.NARRATIVE ->
                    SceneDescriber.describeNarrativeMinimalJson(
                        tracked,
                        bitmap.width.toFloat(),
                        bitmap.height.toFloat()
                    )

                AssistantActivity.AnalysisMode.COUNTS_ONLY ->
                    SceneDescriber.describeCountsOnlyMinimal(
                        boxes.groupingBy { it.label }.eachCount()
                    )
            }

            lastSceneSummary = safelyTrim(sceneJson, 800)

            val jsonFile = File(
                Environment.getExternalStoragePublicDirectory(Environment.DIRECTORY_DOWNLOADS),
                "photo_analysis_${System.currentTimeMillis()}.json"
            ).apply {
                writeText(sceneJson)
            }

            SceneAnalysisResult(
                summary = sceneJson,
                boxes = boxes,
                json = sceneJson,
                filePath = jsonFile.absolutePath,
                labels = labels
            )
        }

    /**
     * Generates a text response from the language model based on user input and selected analysis [mode].
     *
     * @param userInput The prompt or query from the user.
     * @param mode The analysis mode that may influence the generation (not directly used here).
     * @return A string response generated by the LLM.
     */
    override fun generateResponse(userInput: String, mode: AssistantActivity.AnalysisMode): String {
        return com.example.detectask.ml.llm.LLMManager.generate(userInput)
    }

    /**
     * Generates a high-level narrative description of the current or most recent scene.
     *
     * Internally calls [generateResponse] with a preset prompt.
     *
     * @return A narrative-style scene description generated by the LLM.
     */
    override fun generateNarrativeDescription(): String {
        return generateResponse("What does the room look like?", AssistantActivity.AnalysisMode.NARRATIVE)
    }
}
